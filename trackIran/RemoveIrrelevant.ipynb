{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, display\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadJsonFile(filename): \n",
    "    with open(filename, 'r') as f:\n",
    "        DicConfig = json.load(f)\n",
    "    return DicConfig\n",
    "\n",
    "\n",
    "def GlobalDicDeplier(OneDic):\n",
    "    for k,v in OneDic.items():\n",
    "        exec('globals()[k] = v')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Config variables\n"
     ]
    }
   ],
   "source": [
    "DicConfig = LoadJsonFile(os.path.join(os.getcwd(),\"config.json\"))\n",
    "GlobalDicDeplier(DicConfig)\n",
    "sys.path.append(Root)\n",
    "from fun import *\n",
    "\n",
    "print(\"Load Config variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(Root,FolderProject,\"RefFam.pkl\")\n",
    "RefFam = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"RefRT.pkl\")\n",
    "RefRT = LoadPickleOrInit(path)\n",
    "\n",
    "path = os.path.join(Root,FolderProject,\"ISdf.pkl\")\n",
    "OldISdf = LoadPickleOrInit(path)\n",
    "\n",
    "print(\"Load Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstBassineID = ExtractFirstBID(RefRT,OldISdf,bassine_size)\n",
    "datelastaction = RefRT.TWEETUNIXEPOCH.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHORID</th>\n",
       "      <th>AUTHORTWEETID</th>\n",
       "      <th>TWEETID</th>\n",
       "      <th>TWEETUNIXEPOCH</th>\n",
       "      <th>USERID</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450941680</td>\n",
       "      <td>1220041912591306752</td>\n",
       "      <td>1220421444649263105</td>\n",
       "      <td>1579809721</td>\n",
       "      <td>314024921</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21536398</td>\n",
       "      <td>1220421016826105856</td>\n",
       "      <td>1220421444863176705</td>\n",
       "      <td>1579809721</td>\n",
       "      <td>1027021349959688192</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3385500554</td>\n",
       "      <td>1220364979716677632</td>\n",
       "      <td>1220421444993200129</td>\n",
       "      <td>1579809721</td>\n",
       "      <td>920420595996733440</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUTHORID       AUTHORTWEETID              TWEETID  TWEETUNIXEPOCH  \\\n",
       "0  450941680 1220041912591306752  1220421444649263105      1579809721   \n",
       "1   21536398 1220421016826105856  1220421444863176705      1579809721   \n",
       "2 3385500554 1220364979716677632  1220421444993200129      1579809721   \n",
       "\n",
       "                USERID status  \n",
       "0            314024921     ko  \n",
       "1  1027021349959688192     ko  \n",
       "2   920420595996733440     ko  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RefRT.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractQualifiedRT(RefFam,bassine_size,FirstBassineID):\n",
    "\n",
    "    df = RefRT.copy()\n",
    "\n",
    "    BassineID = RefFam.AUTHORTWEETUNIXEPOCH/bassine_size\n",
    "    RefFam[\"BassineID\"] = BassineID.astype(int)\n",
    "    RefFam[\"BassineSize\"] = bassine_size\n",
    "    RefFam = RefFam[RefFam.BassineID>=FirstBassineID]\n",
    "    RefFam.reset_index(drop=False,inplace=True)\n",
    "\n",
    "    df = df[df.AUTHORTWEETID.isin(RefFam.AUTHORTWEETID)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    df = df.merge(RefFam[[\"AUTHORTWEETID\",\"AUTHORTWEETUNIXEPOCH\"]],on=\"AUTHORTWEETID\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddSomeStatsRT(df,bassine_size,bassine_recul,FirstBassineID):\n",
    "\n",
    "    BassineID = df.AUTHORTWEETUNIXEPOCH/bassine_size\n",
    "    df[\"BassineID\"] = BassineID.astype(int)\n",
    "    df[\"BassineSize\"] = bassine_size\n",
    "    df[\"age\"] = df.TWEETUNIXEPOCH - df.AUTHORTWEETUNIXEPOCH\n",
    "    df[\"recul\"] = datelastaction - df.AUTHORTWEETUNIXEPOCH\n",
    "\n",
    "    minreculdf = df.groupby(\"BassineID\")[\"recul\"].min().reset_index()\n",
    "    minreculdf = minreculdf[minreculdf.recul>=bassine_recul]\n",
    "    minreculdf = minreculdf[minreculdf.BassineID>=FirstBassineID]\n",
    "    minreculdf = minreculdf.rename(columns = {\"recul\":\"minrecul\"}).reset_index(drop = True)\n",
    "    \n",
    "    df = df.merge(minreculdf,on=\"BassineID\")\n",
    "    df = df[df.age<=bassine_recul]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildStatsIrrelevant(tempdf,bassine_threshold,bassine_size):\n",
    "\n",
    "    y = tempdf.groupby([\"BassineID\",\"AUTHORTWEETID\"]).size().reset_index().rename(columns = {0:\"f\"})\n",
    "    r = y.groupby('BassineID')['f'].rank(ascending=False).reset_index(drop=True)\n",
    "    y[\"Rank\"] = r\n",
    "    y.sort_values(by=[\"BassineID\",\"f\"],ascending=False,inplace=True)\n",
    "    y.reset_index(drop = True,inplace = True)\n",
    "    y[\"cumsumf\"] = y.groupby(\"BassineID\")[\"f\"].apply(lambda x: x.cumsum())\n",
    "    sumdf = y.groupby(\"BassineID\")[\"f\"].sum().reset_index().rename(columns = {\"f\":\"sum\"})\n",
    "    y = y.merge(sumdf,on=\"BassineID\")\n",
    "    y[\"p\"] = (100*y.cumsumf) / y[\"sum\"]\n",
    "    y = y[y.p<bassine_threshold]\n",
    "    y[\"BassineSize\"]  = bassine_size\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateISdf(RefFam,bassine_size,FirstBassineID,bassine_recul,bassine_threshold,Root,FolderProject):\n",
    "    \n",
    "    print(\"Extracting Qualified RT\")\n",
    "    df = ExtractQualifiedRT(RefFam,bassine_size,FirstBassineID)\n",
    "    print(\"rows : \",str(len(df)))\n",
    "    \n",
    "    if len(df>0):\n",
    "        print(\"Add Some Stats to Qualified RT\")\n",
    "        df = AddSomeStatsRT(df,bassine_size,bassine_recul,FirstBassineID)\n",
    "        print(\"rows : \",str(len(df)))\n",
    "        \n",
    "    else:\n",
    "        print(\"Not enough data\")\n",
    "        return None\n",
    "    \n",
    "    if len(df>0):\n",
    "        print(\"Compute Stats for Relevant RT\")\n",
    "        ISdf = BuildStatsIrrelevant(df,bassine_threshold,bassine_size)\n",
    "        addrow = len(ISdf)\n",
    "        print(\"Stack new data to OldISdf\")\n",
    "        ISdf = OldISdf.append(ISdf,ignore_index=True)\n",
    "        ISdf.reset_index(drop=True,inplace=True)\n",
    "        finalrow = len(ISdf)\n",
    "        print(\"Save ISdf.pkl on disk\")\n",
    "        PickleDump(os.path.join(Root,FolderProject,\"ISdf.pkl\"),ISdf)\n",
    "        print(str(addrow),\" ont été rajoutées\")\n",
    "        print(str(finalrow),\" au total dans le fichier ISdf.pkl\")\n",
    "    else:\n",
    "        print(\"Not enough data\")\n",
    "        return None\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Qualified RT\n",
      "rows :  897858\n",
      "Add Some Stats to Qualified RT\n",
      "rows :  446443\n",
      "Compute Stats for Relevant RT\n",
      "Stack new data to OldISdf\n",
      "Save ISdf.pkl on disk\n",
      "4545  ont été rajoutées\n",
      "4545  au total dans le fichier ISdf.pkl\n"
     ]
    }
   ],
   "source": [
    "UpdateISdf(RefFam,\n",
    "           bassine_size,\n",
    "           FirstBassineID,\n",
    "           bassine_recul,\n",
    "           bassine_threshold,\n",
    "           Root,\n",
    "           FolderProject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Qualified RT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bca2ddb473a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting Qualified RT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractQualifiedRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRefFam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbassine_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFirstBassineID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rows : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-15cffb647fe0>\u001b[0m in \u001b[0;36mExtractQualifiedRT\u001b[0;34m(RefFam, bassine_size, FirstBassineID)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mBassineID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRefFam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTHORTWEETUNIXEPOCH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbassine_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mRefFam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BassineID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBassineID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mRefFam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BassineSize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbassine_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mRefFam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRefFam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRefFam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBassineID\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mFirstBassineID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5880\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[0;32m-> 5882\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5883\u001b[0m             )\n\u001b[1;32m   5884\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             raise ValueError(\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0;34m\"Cannot convert non-finite values (NA or inf) to \"\u001b[0m \u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             )\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "print(\"Extracting Qualified RT\")\n",
    "df = ExtractQualifiedRT(RefFam,bassine_size,FirstBassineID)\n",
    "print(\"rows : \",str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Add Some Stats to Qualified RT\")\n",
    "df = AddSomeStatsRT(df,bassine_size,bassine_recul,FirstBassineID)\n",
    "print(\"rows : \",str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compute Stats for Relevant RT\")\n",
    "ISdf = BuildStatsIrrelevant(df,bassine_threshold,bassine_size)\n",
    "addrow = len(ISdf)\n",
    "print(\"Stack new data to OldISdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISdf = OldISdf.append(ISdf,ignore_index=True)\n",
    "ISdf.reset_index(drop=True,inplace=True)\n",
    "finalrow = len(ISdf)\n",
    "print(\"Save ISdf.pkl on disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PickleDump(os.path.join(Root,FolderProject,\"ISdf.pkl\"),ISdf)\n",
    "print(str(addrow),\" ont été rajoutées\")\n",
    "print(str(finalrow),\" au total dans le fichier ISdf.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
