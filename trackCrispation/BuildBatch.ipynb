{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION!\n",
    "# A lancer depuis le Project Folder\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, display\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadJsonFile(filename): \n",
    "    with open(filename, 'r') as f:\n",
    "        DicConfig = json.load(f)\n",
    "    return DicConfig\n",
    "\n",
    "\n",
    "def GlobalDicDeplier(OneDic):\n",
    "    for k,v in OneDic.items():\n",
    "        exec('globals()[k] = v')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Config variables\n"
     ]
    }
   ],
   "source": [
    "DicConfig = LoadJsonFile(os.path.join(os.getcwd(),\"config.json\"))\n",
    "GlobalDicDeplier(DicConfig)\n",
    "sys.path.append(Root)\n",
    "from fun import *\n",
    "print(\"Load Config variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune Error 420\n",
      "Nombre de tweets :  431\n",
      "errors :  0\n",
      "Read Tweets\n"
     ]
    }
   ],
   "source": [
    "tweetslist,errors = ReadTweetsToList(Root,FolderProject,TweetsFilename)\n",
    "print(\"Nombre de tweets : \", str(len(tweetslist)))\n",
    "print(\"errors : \",str(errors))\n",
    "print(\"Read Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 Lignes correctement supprimées\n"
     ]
    }
   ],
   "source": [
    "# Clean Flow\n",
    "RowsToRemove = len(tweetslist) + errors\n",
    "commandbash = WriteCleaningScript(RowsToRemove,Root,FolderProject,TweetsFilename)\n",
    "resultat = subprocess.call(commandbash,shell = True)\n",
    "if resultat == 0:\n",
    "    print(str(RowsToRemove),\"Lignes correctement supprimées\")\n",
    "else:\n",
    "    print(\"Problème lors du cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert tweets to dataframe\n"
     ]
    }
   ],
   "source": [
    "f = \"%a %b %d %H:%M:%S +0000 %Y\"\n",
    "df = pd.DataFrame(tweetslist)\n",
    "df.TWEETTIMESTAMP = pd.to_datetime(df.TWEETTIMESTAMP,format = f, errors='ignore')\n",
    "df[\"TWEETUNIXEPOCH\"] = df.TWEETTIMESTAMP.map(lambda a : a.value // 10**9)\n",
    "df.TWEETUNIXEPOCH = df.TWEETUNIXEPOCH + 3600\n",
    "print(\"Convert tweets to dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean errors\n"
     ]
    }
   ],
   "source": [
    "df = df.replace({'True':True,'False':False})\n",
    "df.USERID = pd.to_numeric(df.USERID,errors=\"coerce\")\n",
    "df.USERFOLLOWERS = pd.to_numeric(df.USERFOLLOWERS,errors=\"coerce\")\n",
    "df.TWEETID = pd.to_numeric(df.TWEETID,errors=\"coerce\")\n",
    "df.AUTHORID = pd.to_numeric(df.AUTHORID,errors=\"coerce\")\n",
    "df.AUTHORFOLLOWERS = pd.to_numeric(df.AUTHORFOLLOWERS,errors=\"coerce\")\n",
    "df.AUTHORTWEETID = pd.to_numeric(df.AUTHORTWEETID,errors=\"coerce\")\n",
    "df.TWEETUNIXEPOCH = pd.to_numeric(df.TWEETUNIXEPOCH,errors=\"coerce\")\n",
    "print(\"Clean errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build dfsimple and dfrt dataframes\n"
     ]
    }
   ],
   "source": [
    "dfrt = df.copy()[df.ISRETWEET]\n",
    "dfrt.dropna(inplace=True)\n",
    "dfrt.AUTHORTWEETTIMESTAMP = pd.to_datetime(dfrt.AUTHORTWEETTIMESTAMP,format = f, errors='ignore')\n",
    "dfrt[\"AUTHORTWEETUNIXEPOCH\"] = dfrt.AUTHORTWEETTIMESTAMP.map(lambda a : a.value // 10**9)\n",
    "dfrt.AUTHORTWEETUNIXEPOCH = dfrt.AUTHORTWEETUNIXEPOCH + 3600\n",
    "\n",
    "\n",
    "dfsimple = df.copy()[~df.ISRETWEET]\n",
    "vartoremove = [ 'AUTHORNAME',\n",
    " 'AUTHORFNAME',\n",
    " 'AUTHORID',\n",
    " 'AUTHORVERIFIED',\n",
    " 'AUTHORDESCRIPTION',\n",
    " 'AUTHORFOLLOWERS',\n",
    " 'AUTHORTWEETID',\n",
    " 'AUTHORTWEETCONTENT',\n",
    " 'AUTHORTWEETTIMESTAMP']\n",
    "dfsimple.drop(columns=vartoremove,inplace=True)\n",
    "dfsimple.dropna(inplace=True)\n",
    "\n",
    "print(\"Build dfsimple and dfrt dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Influenceur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build batch influenceurs\n"
     ]
    }
   ],
   "source": [
    "keepvar = [\"AUTHORID\",\"AUTHORNAME\",\"AUTHORFNAME\",\"AUTHORDESCRIPTION\",\"AUTHORFOLLOWERS\"]\n",
    "TableInf = dfrt.copy()\n",
    "TableInf = TableInf[keepvar]\n",
    "TableInf = TableInf.groupby(\"AUTHORID\").first().reset_index()\n",
    "print(\"Build batch influenceurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build batch RT\n"
     ]
    }
   ],
   "source": [
    "keepvar = [\"TWEETID\",\"AUTHORTWEETID\",\"USERID\",\"AUTHORID\",\"TWEETUNIXEPOCH\"]\n",
    "TableRT = dfrt.copy()\n",
    "TableRT = TableRT[keepvar]\n",
    "TableRT[\"status\"] = \"ko\"\n",
    "print(\"Build batch RT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Tweet Repris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build batch tweet famous\n"
     ]
    }
   ],
   "source": [
    "keepvar = [\"AUTHORID\",\"AUTHORTWEETID\",\"AUTHORTWEETCONTENT\",\"AUTHORTWEETUNIXEPOCH\"]\n",
    "TableFamousTweet = dfrt.copy()\n",
    "TableFamousTweet = TableFamousTweet[keepvar]\n",
    "TableFamousTweet.drop_duplicates(inplace = True)\n",
    "TableFamousTweet[\"status\"] = \"ko\"\n",
    "print(\"Build batch tweet famous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save batchs\n"
     ]
    }
   ],
   "source": [
    "PickleDump(os.path.join(Root,FolderProject,\"BatchFamousTweet.pkl\"),TableFamousTweet)\n",
    "PickleDump(os.path.join(Root,FolderProject,\"BatchRT.pkl\"),TableRT)\n",
    "PickleDump(os.path.join(Root,FolderProject,\"BatchInf.pkl\"),TableInf)\n",
    "print(\"Save batchs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write logs\n"
     ]
    }
   ],
   "source": [
    "CurrentTimeString = GetCurrentTime()\n",
    "DateDebut = str(pd.to_datetime(dfrt.TWEETUNIXEPOCH.min(), unit='s'))\n",
    "DateFin = str(pd.to_datetime(dfrt.TWEETUNIXEPOCH.max(), unit='s'))\n",
    "SecondsElapsed = dfrt.TWEETUNIXEPOCH.max() - dfrt.TWEETUNIXEPOCH.min()\n",
    "DelayFormatted = SecondsToDelayFormat(SecondsElapsed)\n",
    "\n",
    "nRetweets = len(TableRT)\n",
    "nInfluenceurs = len(TableInf)\n",
    "nFamousTweets = len(TableFamousTweet)\n",
    "nUsers = len(np.unique(TableRT.USERID))\n",
    "\n",
    "BatchLogs = {\"BatchDate\" : CurrentTimeString,\n",
    "\"StartingDate\" : DateDebut,\n",
    "\"EndingDate\" : DateFin,\n",
    "\"Delay\" : DelayFormatted,\n",
    "\"nRT\" : nRetweets,\n",
    "\"nInf\" : nInfluenceurs,\n",
    "\"nFam\" : nFamousTweets,\n",
    "\"nUse\" : nUsers}\n",
    "\n",
    "filename = os.path.join(Root,FolderProject,\"Batch.log\")\n",
    "AppendStringToFile(filename,BatchLogs)\n",
    "\n",
    "print(\"Write logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
