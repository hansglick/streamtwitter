{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, display\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "french_stopwords = list(fr_stop)\n",
    "from scipy import stats\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadJsonFile(filename): \n",
    "    with open(filename, 'r') as f:\n",
    "        DicConfig = json.load(f)\n",
    "    return DicConfig\n",
    "\n",
    "\n",
    "def GlobalDicDeplier(OneDic):\n",
    "    for k,v in OneDic.items():\n",
    "        exec('globals()[k] = v')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Config variables\n"
     ]
    }
   ],
   "source": [
    "DicConfig = LoadJsonFile(os.path.join(os.getcwd(),\"config.json\"))\n",
    "GlobalDicDeplier(DicConfig)\n",
    "sys.path.append(Root)\n",
    "from fun import *\n",
    "\n",
    "print(\"Load Config variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reffam = PickleLoad(os.path.join(Root,FolderProject,\"RefFam.pkl\"))\n",
    "refrt = PickleLoad(os.path.join(Root,FolderProject,\"RefRT.pkl\"))\n",
    "refrt[\"EPOK\"] = refrt.TWEETUNIXEPOCH / 86400\n",
    "refrt[\"EPOK\"] = refrt.EPOK.astype(int)\n",
    "TweetsStats = refrt.groupby([\"AUTHORTWEETID\",\"EPOK\"]).size().reset_index().rename(columns = {0:\"w\"})\n",
    "TweetsToAnalyse = reffam[[\"AUTHORTWEETID\",\"AUTHORTWEETCONTENT\",\"AUTHORTWEETUNIXEPOCH\"]].\\\n",
    "rename(columns = {\"AUTHORTWEETID\":\"TWEETID\",\"AUTHORTWEETCONTENT\":\"TWEETCONTENT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493208, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refrt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tfidf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(RemoveWordsPeriod,TooFrequentThreshold,TooInfrequentThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data!\n"
     ]
    }
   ],
   "source": [
    "corpus.LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.ProcessCorpus(TweetsToAnalyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3\n",
      "2 / 3\n",
      "3 / 3\n"
     ]
    }
   ],
   "source": [
    "corpus.ComputeCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.SaveOnDisk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = corpus.DocsRepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24857, 6)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add some informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 36.4 ms, total: 1.24 s\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = tfidf.merge(TweetsStats,left_on=\"tweetid\",right_on=\"AUTHORTWEETID\")\n",
    "tfidf.sort_values(by=[\"w\",\"tweetid\"],inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du nuage de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.COMPTEUR['salamé']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>Rank</th>\n",
       "      <th>f</th>\n",
       "      <th>idf</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>word</th>\n",
       "      <th>AUTHORTWEETID</th>\n",
       "      <th>EPOK</th>\n",
       "      <th>w</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27543</th>\n",
       "      <td>8793</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>mohamed</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18292</td>\n",
       "      <td>259</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27545</th>\n",
       "      <td>8793</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>tête</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18292</td>\n",
       "      <td>259</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27547</th>\n",
       "      <td>8793</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>appelle</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18292</td>\n",
       "      <td>259</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27549</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>mieux</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18292</td>\n",
       "      <td>259</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27551</th>\n",
       "      <td>8793</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>musulmans</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18292</td>\n",
       "      <td>259</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27553</th>\n",
       "      <td>8793</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>êtes</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18292</td>\n",
       "      <td>259</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27542</th>\n",
       "      <td>8793</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>mohamed</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18291</td>\n",
       "      <td>66</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27544</th>\n",
       "      <td>8793</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>tête</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18291</td>\n",
       "      <td>66</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27546</th>\n",
       "      <td>8793</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>appelle</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18291</td>\n",
       "      <td>66</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27548</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>mieux</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18291</td>\n",
       "      <td>66</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27550</th>\n",
       "      <td>8793</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>musulmans</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18291</td>\n",
       "      <td>66</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27552</th>\n",
       "      <td>8793</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>êtes</td>\n",
       "      <td>1223007786315014144</td>\n",
       "      <td>18291</td>\n",
       "      <td>66</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          D  Rank    f  idf             tweetid       word  \\\n",
       "27543  8793     1    7    7 1223007786315014144    mohamed   \n",
       "27545  8793     2   42    5 1223007786315014144       tête   \n",
       "27547  8793     3   44    5 1223007786315014144    appelle   \n",
       "27549  8793     4   60    5 1223007786315014144      mieux   \n",
       "27551  8793     5  106    4 1223007786315014144  musulmans   \n",
       "27553  8793     6  108    4 1223007786315014144       êtes   \n",
       "27542  8793     1    7    7 1223007786315014144    mohamed   \n",
       "27544  8793     2   42    5 1223007786315014144       tête   \n",
       "27546  8793     3   44    5 1223007786315014144    appelle   \n",
       "27548  8793     4   60    5 1223007786315014144      mieux   \n",
       "27550  8793     5  106    4 1223007786315014144  musulmans   \n",
       "27552  8793     6  108    4 1223007786315014144       êtes   \n",
       "\n",
       "            AUTHORTWEETID   EPOK    w  power  \n",
       "27543 1223007786315014144  18292  259   1848  \n",
       "27545 1223007786315014144  18292  259   1384  \n",
       "27547 1223007786315014144  18292  259   1372  \n",
       "27549 1223007786315014144  18292  259   1292  \n",
       "27551 1223007786315014144  18292  259   1144  \n",
       "27553 1223007786315014144  18292  259   1139  \n",
       "27542 1223007786315014144  18291   66    471  \n",
       "27544 1223007786315014144  18291   66    353  \n",
       "27546 1223007786315014144  18291   66    350  \n",
       "27548 1223007786315014144  18291   66    329  \n",
       "27550 1223007786315014144  18291   66    292  \n",
       "27552 1223007786315014144  18291   66    290  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[tfidf.tweetid == 1223007786315014151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-01-31 12:48:31')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(refrt.TWEETUNIXEPOCH[refrt.AUTHORTWEETID==1223210808169070592].min(),unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-01-31 20:55:06')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(refrt.TWEETUNIXEPOCH[refrt.AUTHORTWEETID==1223210808169070592].max(),unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>Rank</th>\n",
       "      <th>f</th>\n",
       "      <th>idf</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>word</th>\n",
       "      <th>AUTHORTWEETID</th>\n",
       "      <th>EPOK</th>\n",
       "      <th>w</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20428</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223510356439568384</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223510356439568384</td>\n",
       "      <td>18293</td>\n",
       "      <td>432</td>\n",
       "      <td>1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25154</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223210808169070592</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223210808169070592</td>\n",
       "      <td>18292</td>\n",
       "      <td>424</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223517174683328256</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223517174683328256</td>\n",
       "      <td>18293</td>\n",
       "      <td>379</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223532135539204096</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223532135539204096</td>\n",
       "      <td>18293</td>\n",
       "      <td>312</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12184</th>\n",
       "      <td>8793</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223990092861202432</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223990092861202432</td>\n",
       "      <td>18294</td>\n",
       "      <td>292</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16211</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223699982777298944</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223699982777298944</td>\n",
       "      <td>18294</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17447</th>\n",
       "      <td>8793</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223657376768843520</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223657376768843520</td>\n",
       "      <td>18294</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17820</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223644846486949888</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223644846486949888</td>\n",
       "      <td>18294</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18591</th>\n",
       "      <td>8793</td>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223622032249638656</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223622032249638656</td>\n",
       "      <td>18294</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>8793</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>1223307764220469248</td>\n",
       "      <td>mila</td>\n",
       "      <td>1223307764220469248</td>\n",
       "      <td>18293</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          D  Rank    f  idf             tweetid  word       AUTHORTWEETID  \\\n",
       "20428  8793     4  136    4 1223510356439568384  mila 1223510356439568384   \n",
       "25154  8793     4  136    4 1223210808169070592  mila 1223210808169070592   \n",
       "20337  8793     4  136    4 1223517174683328256  mila 1223517174683328256   \n",
       "20155  8793     4  136    4 1223532135539204096  mila 1223532135539204096   \n",
       "12184  8793     3  136    4 1223990092861202432  mila 1223990092861202432   \n",
       "...     ...   ...  ...  ...                 ...   ...                 ...   \n",
       "16211  8793     4  136    4 1223699982777298944  mila 1223699982777298944   \n",
       "17447  8793     3  136    4 1223657376768843520  mila 1223657376768843520   \n",
       "17820  8793     4  136    4 1223644846486949888  mila 1223644846486949888   \n",
       "18591  8793     7  136    4 1223622032249638656  mila 1223622032249638656   \n",
       "23446  8793     3  136    4 1223307764220469248  mila 1223307764220469248   \n",
       "\n",
       "        EPOK    w  power  \n",
       "20428  18293  432   1801  \n",
       "25154  18292  424   1768  \n",
       "20337  18293  379   1580  \n",
       "20155  18293  312   1301  \n",
       "12184  18294  292   1217  \n",
       "...      ...  ...    ...  \n",
       "16211  18294    1      4  \n",
       "17447  18294    1      4  \n",
       "17820  18294    1      4  \n",
       "18591  18294    1      4  \n",
       "23446  18293    1      4  \n",
       "\n",
       "[156 rows x 10 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[tfidf.word==\"mila\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tête',\n",
       " 'appelle',\n",
       " 'mohamed',\n",
       " 'crache',\n",
       " 'musulmans',\n",
       " 'mieux',\n",
       " 'êtes',\n",
       " 'https',\n",
       " 'mzjphegtsq']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer(reffam.AUTHORTWEETCONTENT[reffam.AUTHORTWEETID==1223007786315014144].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Dans la tête des gens comme il s\\'appelle Mohamed s\\'il crache sur les musulmans, c\\'est encore mieux. Vous êtes un p… https://t.co/mzJPHegtSQ'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reffam.AUTHORTWEETCONTENT[reffam.AUTHORTWEETID==1223007786315014144].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>Rank</th>\n",
       "      <th>f</th>\n",
       "      <th>idf</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>word</th>\n",
       "      <th>AUTHORTWEETID</th>\n",
       "      <th>EPOK</th>\n",
       "      <th>w</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>8793</td>\n",
       "      <td>1</td>\n",
       "      <td>706</td>\n",
       "      <td>3</td>\n",
       "      <td>1223938187355140096</td>\n",
       "      <td>wallah</td>\n",
       "      <td>1223938187355140096</td>\n",
       "      <td>18294</td>\n",
       "      <td>6399</td>\n",
       "      <td>16139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>8793</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>lycéens</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>18293</td>\n",
       "      <td>3194</td>\n",
       "      <td>20357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811</th>\n",
       "      <td>8793</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>garde</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>18293</td>\n",
       "      <td>3194</td>\n",
       "      <td>19602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19812</th>\n",
       "      <td>8793</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>vue</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>18293</td>\n",
       "      <td>3194</td>\n",
       "      <td>18992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>8793</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>place</td>\n",
       "      <td>1223557159285337856</td>\n",
       "      <td>18293</td>\n",
       "      <td>3194</td>\n",
       "      <td>18726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          D  Rank    f  idf             tweetid     word       AUTHORTWEETID  \\\n",
       "13391  8793     1  706    3 1223938187355140096   wallah 1223938187355140096   \n",
       "19810  8793     1   15    6 1223557159285337856  lycéens 1223557159285337856   \n",
       "19811  8793     2   19    6 1223557159285337856    garde 1223557159285337856   \n",
       "19812  8793     3   23    6 1223557159285337856      vue 1223557159285337856   \n",
       "19813  8793     4   25    6 1223557159285337856    place 1223557159285337856   \n",
       "\n",
       "        EPOK     w  power  \n",
       "13391  18294  6399  16139  \n",
       "19810  18293  3194  20357  \n",
       "19811  18293  3194  19602  \n",
       "19812  18293  3194  18992  \n",
       "19813  18293  3194  18726  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[\"power\"] = tfidf.w * tfidf.idf\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = tfidf.groupby([\"word\",\"EPOK\"])[\"power\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud.sort_values(by=[\"EPOK\",\"power\"],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud[\"rank\"] = wordcloud.groupby([\"EPOK\"]).cumcount()+1\n",
    "wordcloud.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word   EPOK  power  rank\n",
      "0        allah  18294  26703     1\n",
      "1       wallah  18294  25874     2\n",
      "2      londres  18294  25809     3\n",
      "3      attaque  18294  19625     4\n",
      "4      couteau  18294  17887     5\n",
      "5    personnes  18294  16392     6\n",
      "6   terroriste  18294  15936     7\n",
      "7       police  18294  15643     8\n",
      "8        islam  18294  13209     9\n",
      "9          ans  18294  12693    10\n",
      "10     haddach  18294  12612    11\n",
      "11      rachid  18294  12472    12\n",
      "12      france  18294  11827    13\n",
      "13    vraiment  18294  11018    14\n",
      "14      abattu  18294  11016    15\n",
      "15      jamais  18294  10516    16\n",
      "16       homme  18294   9881    17\n",
      "17      femmes  18294   9797    18\n",
      "18    attentat  18294   9742    19\n",
      "19    français  18294   9632    20\n",
      "\n",
      "           word   EPOK  power  rank\n",
      "507  traduction  18293  29196     1\n",
      "508     lycéens  18293  25979     2\n",
      "509       garde  18293  24690     3\n",
      "510         vue  18293  23161     4\n",
      "511       place  18293  20878     5\n",
      "512       vient  18293  19006     6\n",
      "513       islam  18293  17257     7\n",
      "514       allah  18293  17013     8\n",
      "515    insulter  18293  15488     9\n",
      "516  homophobie  18293  13937    10\n",
      "517        anti  18293  12865    11\n",
      "518   homophobe  18293  12112    12\n",
      "519        êtes  18293  11817    13\n",
      "520         ans  18293  11231    14\n",
      "521       vidéo  18293  11123    15\n",
      "522     raciste  18293   9970    16\n",
      "523        mila  18293   9635    17\n",
      "524   agression  18293   9256    18\n",
      "525  répression  18293   9252    19\n",
      "526     affaire  18293   8425    20\n",
      "\n",
      "           word   EPOK  power  rank\n",
      "1081   ministre  18292  19678     1\n",
      "1082    enfants  18292  17747     2\n",
      "1083      islam  18292  14623     3\n",
      "1084     france  18292  13027     4\n",
      "1085   religion  18292  12007     5\n",
      "1086      allah  18292  10142     6\n",
      "1087        ans  18292   8877     7\n",
      "1088      vidéo  18292   8512     8\n",
      "1089     hommes  18292   8148     9\n",
      "1090    racisme  18292   8144    10\n",
      "1091     élèves  18292   8026    11\n",
      "1092      salam  18292   8012    12\n",
      "1093       paix  18292   7978    13\n",
      "1094     blancs  18292   7782    14\n",
      "1095      coran  18292   7745    15\n",
      "1096  agression  18292   7410    16\n",
      "1097       mère  18292   7402    17\n",
      "1098      femme  18292   7090    18\n",
      "1099      rebeu  18292   7056    19\n",
      "1100     petite  18292   6954    20\n",
      "\n",
      "             word   EPOK  power  rank\n",
      "1475          léa  18291   1152     1\n",
      "1476       salamé  18291   1152     2\n",
      "1477        appel  18291   1127     3\n",
      "1478       fillon  18291   1120     4\n",
      "1479    violences  18291   1099     5\n",
      "1480        texte  18291   1035     6\n",
      "1481  journaliste  18291    882     7\n",
      "1482         lieu  18291    829     8\n",
      "1483       demain  18291    773     9\n",
      "1484      appelle  18291    758    10\n",
      "1485      mohamed  18291    471    11\n",
      "1486         tête  18291    385    12\n",
      "1487         êtes  18291    330    13\n",
      "1488        mieux  18291    329    14\n",
      "1489    musulmans  18291    292    15\n",
      "1490          fin  18291    278    16\n",
      "1491      victime  18291    278    17\n",
      "1492          svp  18291    264    18\n",
      "1493    homophobe  18291    263    19\n",
      "1494       marier  18291    257    20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in wordcloud.EPOK.unique():\n",
    "    print(wordcloud[wordcloud.EPOK==e].head(20))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tweet analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['w'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-a8e5975c1642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmytweetid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweetid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmytweetid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1224088992150409216\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExploreTweetTreatment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytweetid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreffam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-168-d1b7e5f43e23>\u001b[0m in \u001b[0;36mExploreTweetTreatment\u001b[0;34m(mytweetid, reffam, tfidf)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreffam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTHORTWEETCONTENT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreffam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTHORTWEETID\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmytweetid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweetid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmytweetid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"idf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Rank\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['w'] not in index\""
     ]
    }
   ],
   "source": [
    "mytweetid = np.random.choice(a = tfidf.tweetid.unique())\n",
    "mytweetid = 1224088992150409216\n",
    "content,tokens,details = ExploreTweetTreatment(mytweetid,reffam,tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affaire #Mila : la Parquet fait machine arrière, #Belloubet se déjuge et les islamo-gauchistes font grise mine.\n",
      "Con… https://t.co/Un4483y1j4\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affaire', 'mila', 'parquet', 'machine', 'arrière', 'belloubet', 'déjuge', 'islamo', 'gauchistes', 'grise', 'mine', 'con', 'https', 'un4483y1j4']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'parquet',\n",
       "  'idf': 7.477523438381578,\n",
       "  'Rank': 1,\n",
       "  'f': 7,\n",
       "  'w': 116,\n",
       "  'WordPercentile': 0.059632540356839424},\n",
       " {'word': 'belloubet',\n",
       "  'idf': 7.226209010100671,\n",
       "  'Rank': 2,\n",
       "  'f': 9,\n",
       "  'w': 116,\n",
       "  'WordPercentile': 0.07735060889266497},\n",
       " {'word': 'islamo',\n",
       "  'idf': 5.989446382951745,\n",
       "  'Rank': 3,\n",
       "  'f': 31,\n",
       "  'w': 116,\n",
       "  'WordPercentile': 0.20897054658736902},\n",
       " {'word': 'affaire',\n",
       "  'idf': 5.079628165583207,\n",
       "  'Rank': 4,\n",
       "  'f': 77,\n",
       "  'w': 116,\n",
       "  'WordPercentile': 0.4540321438685925},\n",
       " {'word': 'mila',\n",
       "  'idf': 4.186991624606942,\n",
       "  'Rank': 5,\n",
       "  'f': 188,\n",
       "  'w': 116,\n",
       "  'WordPercentile': 0.728529453412631}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExploreTweetTreatment(mytweetid,reffam,tfidf):\n",
    "    content = reffam.AUTHORTWEETCONTENT[reffam.AUTHORTWEETID==mytweetid].iloc[0]\n",
    "    tokens = Tokenizer(content)\n",
    "    details = tfidf[tfidf.tweetid==mytweetid][[\"word\",\"idf\",\"Rank\",\"f\",\"w\"]].\\\n",
    "    to_dict(orient=\"records\")\n",
    "    return content,tokens,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus():\n",
    "    \n",
    "    # Initialisation de l'objet\n",
    "    def __init__(self,RemoveWordsPeriod,TooFrequentThreshold,TooInfrequentThreshold):\n",
    "        \n",
    "        self.WORDS2TWEETS = pd.DataFrame()\n",
    "        self.DOCSTOUCHED = pd.DataFrame()\n",
    "        self.COMPTEUR = {}\n",
    "        self.BATCH_WORDS2TWEETS = pd.DataFrame()\n",
    "        self.BATCH_DOCSTOUCHED = pd.DataFrame()\n",
    "        self.BATCH_COMPTEUR = {}\n",
    "        self.BATCH_V = []\n",
    "        self.DocsRepresentation = pd.DataFrame()\n",
    "        self.RemoveWordsPeriod = RemoveWordsPeriod\n",
    "        self.TooFrequentThreshold = TooFrequentThreshold\n",
    "        self.TooInfrequentThreshold = TooInfrequentThreshold\n",
    "        \n",
    "        self.LastDate = 0\n",
    "     \n",
    "    \n",
    "    def LoadData(self):\n",
    "        \n",
    "        self.WORDS2TWEETS = LoadPickleOrInit(os.path.join(Root,FolderProject,\"tfidf_words2tweets.pkl\"))\n",
    "        self.DOCSTOUCHED = LoadPickleOrInit(os.path.join(Root,FolderProject,\"tfidf_docstouched.pkl\"))\n",
    "        self.COMPTEUR = LoadPickleOrInit(os.path.join(Root,FolderProject,\"tfidf_compteur.pkl\"),typeobj=\"dic\")\n",
    "        self.DocsRepresentation = LoadPickleOrInit(os.path.join(Root,FolderProject,\"tfidf_DocsRepresentation.pkl\"))\n",
    "        self.LastDate = LoadPickleOrInit(os.path.join(Root,FolderProject,\"tfidf_lastdate.pkl\"),typeobj=\"0\")\n",
    "        \n",
    "        if len(self.DOCSTOUCHED)==0:\n",
    "            print(\"No data!\")\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def SaveOnDisk(self):\n",
    "        \n",
    "        PickleDump(os.path.join(Root,FolderProject,\"tfidf_compteur.pkl\"),self.COMPTEUR)\n",
    "        PickleDump(os.path.join(Root,FolderProject,\"tfidf_docstouched.pkl\"),self.DOCSTOUCHED)\n",
    "        PickleDump(os.path.join(Root,FolderProject,\"tfidf_words2tweets.pkl\"),self.WORDS2TWEETS)\n",
    "        PickleDump(os.path.join(Root,FolderProject,\"tfidf_DocsRepresentation.pkl\"),self.DocsRepresentation)\n",
    "        PickleDump(os.path.join(Root,FolderProject,\"tfidf_lastdate.pkl\"),self.LastDate)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # EVALUATION de la variable globale |D|\n",
    "    # i.e. le nombre de documents, i.e. les tweets\n",
    "    def EvaluateD(self):\n",
    "        if len(self.WORDS2TWEETS)>0:\n",
    "            res = len(np.unique(self.WORDS2TWEETS.tweetid))\n",
    "        else:\n",
    "            res = 0\n",
    "        return res\n",
    "    \n",
    "    # CREATION de la liste de batch\n",
    "    def ProcessCorpus(self,TweetsDataFrame):\n",
    "        \n",
    "        tweetsdf = TweetsDataFrame.copy()\n",
    "        \n",
    "        if len(self.WORDS2TWEETS)>0:\n",
    "            a = self.WORDS2TWEETS.tweetid.unique()\n",
    "            b = tweetsdf.TWEETID\n",
    "            fil = ~b.isin(a)\n",
    "            tweetsdf = tweetsdf[fil]\n",
    "            \n",
    "        tweetsdf = tweetsdf.copy()[tweetsdf.AUTHORTWEETUNIXEPOCH>self.LastDate]\n",
    "        ListOfTweetsDF = SplitTweetsToAnalyse(tweetsdf,self.RemoveWordsPeriod)\n",
    "        self.WaitingCorpusList = ListOfTweetsDF\n",
    "        \n",
    "        if len(ListOfTweetsDF)>0:\n",
    "            self.LastDate = self.WaitingCorpusList[-1].AUTHORTWEETUNIXEPOCH.max()\n",
    "        \n",
    "        return None\n",
    "        \n",
    "        \n",
    "    # TRAITEMENT DE LA LISTE DE BATCH\n",
    "    def ComputeCorpus(self):\n",
    "        for iddf,df in enumerate(self.WaitingCorpusList):\n",
    "            print(str(iddf+1),\"/\",str(len(self.WaitingCorpusList)))\n",
    "            self.AddCorpus(df)\n",
    "            self.BuildDocsRepresentation()\n",
    "        return None\n",
    "            \n",
    "            \n",
    "    # TRAITEMENT D'UN BATCH\n",
    "    def AddCorpus(self,tweetsdf):     \n",
    "        \n",
    "        if len(tweetsdf)>0:\n",
    "            \n",
    "            # Build les batch df\n",
    "            tweetsdf.TWEETCONTENT = tweetsdf.TWEETCONTENT.map(lambda a : Tokenizer(a))\n",
    "            Words2TweetsDF = DeplyrDF(tweetsdf)\n",
    "            CompteurDic = BooleanCorpusCompteur(tweetsdf.TWEETCONTENT.tolist())\n",
    "            V = list(CompteurDic.keys())\n",
    "            DocsTouched = BuildDocumentsTouched(V,tweetsdf.TWEETCONTENT.tolist())\n",
    "            DocsTouched = pd.DataFrame(data=DocsTouched,index=[0]).T.reset_index().rename(columns = {\"index\":\"word\",0:\"f\"})\n",
    "            \n",
    "            # Remove les mots trop peu fréquents du batch\n",
    "            TooFrequentRaw = int(self.TooFrequentThreshold * len(Words2TweetsDF.tweetid.unique()))\n",
    "            TooInfrequentRaw = int(self.TooInfrequentThreshold * len(Words2TweetsDF.tweetid.unique()))\n",
    "            DocsTouched = DocsTouched.copy()[(DocsTouched.f>TooInfrequentRaw) & (DocsTouched.f<TooFrequentRaw)]\n",
    "            Words2TweetsDF = Words2TweetsDF.merge(DocsTouched,on=\"word\")\n",
    "            Words2TweetsDF = Words2TweetsDF[[\"word\",\"tweetid\"]]\n",
    "            V = DocsTouched.word.tolist()\n",
    "            \n",
    "            # Assignation des batch df\n",
    "            self.BATCH_WORDS2TWEETS = Words2TweetsDF\n",
    "            self.BATCH_DOCSTOUCHED = DocsTouched\n",
    "            self.BATCH_COMPTEUR = CompteurDic\n",
    "            self.BATCH_V = V\n",
    "\n",
    "            \n",
    "                                                                 \n",
    "                                                                 \n",
    "            #  * * * UPDATING PART * * * \n",
    "            #  * * * UPDATING PART * * *\n",
    "            #  * * * UPDATING PART * * *\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # maj du dic\n",
    "            self.COMPTEUR = UpdateCompteurDic(self.COMPTEUR,self.BATCH_COMPTEUR)\n",
    "            \n",
    "            # maj du words2tweets\n",
    "            self.WORDS2TWEETS = pd.concat((self.WORDS2TWEETS,self.BATCH_WORDS2TWEETS),axis=0)\n",
    "            \n",
    "            # maj du docstouched\n",
    "            if len(self.DOCSTOUCHED)>0:\n",
    "                fil = self.DOCSTOUCHED.word.isin(pd.Series(V))\n",
    "                nepastoucher = self.DOCSTOUCHED[~fil]\n",
    "                amodifier = self.DOCSTOUCHED[fil]\n",
    "                amodifier = pd.concat((amodifier,self.BATCH_DOCSTOUCHED),axis = 0)\n",
    "                amodifier = amodifier.groupby(\"word\")[\"f\"].sum().reset_index()\n",
    "                self.DOCSTOUCHED = pd.concat((amodifier,nepastoucher),axis = 0)\n",
    "            else:\n",
    "                self.DOCSTOUCHED = self.BATCH_DOCSTOUCHED\n",
    "                \n",
    "\n",
    "            \n",
    "        # si tweetsdf est vide alors les batch sont vides\n",
    "        else:\n",
    "            self.BATCH_WORDS2TWEETS = pd.DataFrame()\n",
    "            self.BATCH_DOCSTOUCHED = pd.DataFrame()\n",
    "            self.BATCH_COMPTEUR = {}\n",
    "            self.BATCH_V = []\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def BuildDocsRepresentation(self):\n",
    "        \n",
    "        # Si y'a rien dans le batch alors on s'arrête là\n",
    "        if len(self.BATCH_V)==0:\n",
    "            return None\n",
    "        \n",
    "        # Si y'a déjà des idf scores de calculé on doit la mettre à jour\n",
    "        # Le keepdf, contient les mots non présents dans le batch\n",
    "        if len(self.DocsRepresentation)>0:\n",
    "            fil = self.DocsRepresentation.word.isin(pd.Series(self.BATCH_V))\n",
    "            DocsRepresentationKeep = self.DocsRepresentation.copy()[~fil]\n",
    "            DocsRepresentationKeep[\"D\"] = self.EvaluateD()\n",
    "        else:\n",
    "            DocsRepresentationKeep = pd.DataFrame()\n",
    "        \n",
    "        # df intermediaires\n",
    "        fil = self.DOCSTOUCHED.word.isin(pd.Series(self.BATCH_V))\n",
    "        temptouched = self.DOCSTOUCHED.copy()[fil]\n",
    "        fil = self.WORDS2TWEETS.word.isin(pd.Series(self.BATCH_V))\n",
    "        tempwords2 = self.WORDS2TWEETS[fil]        \n",
    "        toadd = temptouched.merge(tempwords2,on=\"word\")\n",
    "        toadd[\"D\"] = self.EvaluateD()   \n",
    "        \n",
    "        # concaténation des scores des anciens mots et des nouveaux mots\n",
    "        solution = pd.concat((toadd,DocsRepresentationKeep),axis = 0, sort = True)    \n",
    "        solution[\"idf\"] = (solution.D / solution.f).map(lambda a : math.log(a))\n",
    "        solution = solution\n",
    "        solution.reset_index(drop = True,inplace = True)\n",
    "        solution.sort_values(by = [\"tweetid\",\"idf\"],ascending=False,inplace=True)\n",
    "        solution.drop_duplicates(inplace = True)\n",
    "        solution['Rank'] = solution.groupby([\"tweetid\"]).cumcount()+1\n",
    "        self.DocsRepresentation = solution\n",
    "        \n",
    "        return None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenizer(randomstring,french_stopwords=french_stopwords):\n",
    "    translator = str.maketrans(string.punctuation,' '*32)\n",
    "    randomstring = randomstring.translate(translator)\n",
    "    randomstring = randomstring.replace(\"’\",\" \")\n",
    "    randomstring = randomstring.replace(\"`\",\" \")\n",
    "    randomstring = randomstring.replace(\"'\",\" \")\n",
    "    randomstring = randomstring.replace(\"“\",\" \")\n",
    "    randomstring = randomstring.replace(\"”\",\" \")\n",
    "    randomstring = randomstring.replace(\"…\",\" \")\n",
    "    randomstring = randomstring.lower()\n",
    "    randomstring = \" \".join(randomstring.split())\n",
    "    words = randomstring.split(\" \")\n",
    "    words = [item for item in words if item not in french_stopwords]\n",
    "    words = [item for item in words if len(item)>2]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentenceCompteur(compteur,words,weight=1):\n",
    "    for w in words:\n",
    "        compteur[w] = compteur.get(w,0) + weight\n",
    "    return compteur\n",
    "\n",
    "def BooleanCorpusCompteur(Corpus):\n",
    "    compteur = {}\n",
    "    for doc in Corpus:\n",
    "        compteur = SentenceCompteur(compteur,doc)\n",
    "    return compteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDocumentsTouched(V,CleanedCorpus):\n",
    "    \n",
    "    DocumentsTouched = {}\n",
    "    for w in V:\n",
    "        for d in CleanedCorpus:\n",
    "            if w in d:\n",
    "                DocumentsTouched[w] = DocumentsTouched.get(w,0) + 1        \n",
    "    \n",
    "    return DocumentsTouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateCompteurDic(OriginalDic,AddDic):\n",
    "    for k,v in AddDic.items():\n",
    "        OriginalDic[k] = OriginalDic.get(k,0) + v\n",
    "    return OriginalDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeplyrDF(TweetsDataFrame):\n",
    "\n",
    "    L = []\n",
    "    for i,row in TweetsDataFrame.iterrows():\n",
    "        tweetid = row[\"TWEETID\"]\n",
    "        tweetcontent = row[\"TWEETCONTENT\"]\n",
    "        tweetcontent = pd.Series(tweetcontent)\n",
    "        tempdf = tweetcontent.to_frame(name = \"word\")\n",
    "        tempdf[\"tweetid\"] = tweetid\n",
    "        L.append(tempdf)\n",
    "\n",
    "    res = pd.concat(L,axis=0)\n",
    "    res.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitTweetsToAnalyse(TweetsToAnalyse,RemoveWordsPeriod):\n",
    "    TweetsToAnalyse[\"TimeElapsed\"] = (TweetsToAnalyse.AUTHORTWEETUNIXEPOCH.max() - TweetsToAnalyse.AUTHORTWEETUNIXEPOCH) / RemoveWordsPeriod\n",
    "    TweetsToAnalyse[\"TimeElapsed\"] = TweetsToAnalyse[\"TimeElapsed\"].astype(int)\n",
    "    idgroup = TweetsToAnalyse.TimeElapsed.unique()\n",
    "    idgroup.sort()\n",
    "    L = []\n",
    "    for idg in idgroup[:-1]:\n",
    "        tempdf = TweetsToAnalyse.copy()[TweetsToAnalyse.TimeElapsed==idg]\n",
    "        L.append(tempdf)\n",
    "    return L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
